{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import joblib\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from keras_balanced_batch_generator import make_generator\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.image import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "examples = []\n",
    "labels = []\n",
    "j=0\n",
    "for file in os.listdir(\"train\"):\n",
    "    j=j+1\n",
    "    if j>1000:\n",
    "        break\n",
    "    img = cv2.resize(cv2.imread('train/' + file, 0), (200, 200), interpolation = cv2.INTER_CUBIC)\n",
    "    examples.append(img)\n",
    "    if file.startswith('cat'):\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "winSize = (200, 200)\n",
    "blockSize = (100, 100)\n",
    "blockStride = (20, 20)\n",
    "cellSize = (50, 50)\n",
    "    \n",
    "def get_hog():\n",
    "    nbins = 9\n",
    "    derivAperture = 1\n",
    "    winSigma = -1.\n",
    "    histogramNormType = 0\n",
    "    L2HysThreshold = 0.2\n",
    "    gammaCorrection = 1\n",
    "    nlevels = 64\n",
    "    signedGradient = True\n",
    "\n",
    "    hog = cv2.HOGDescriptor(winSize, blockSize, blockStride, cellSize, nbins, derivAperture, winSigma,\n",
    "                            histogramNormType, L2HysThreshold, gammaCorrection, nlevels, signedGradient)\n",
    "\n",
    "    return hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog = get_hog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09502677 0.04144662 0.04579363 ... 0.24097471 0.24097471 0.19064368]\n",
      "(1296, 1)\n",
      "(1000, 1296)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hog_descriptors = []\n",
    "j=0\n",
    "for img in examples:\n",
    "    hog_descriptors.append(hog.compute(img))\n",
    "    if j==0:\n",
    "        print(np.squeeze((hog.compute(img))))\n",
    "        print(np.shape((hog.compute(img))))\n",
    "    j=j+1\n",
    "hog_descriptors = np.squeeze(hog_descriptors)\n",
    "print(hog_descriptors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_n = int(0.9 * len(hog_descriptors))\n",
    "train_examples, test_examples, train_hog_descriptors, test_hog_descriptors, train_labels, test_labels =\\\n",
    "    train_test_split(examples, hog_descriptors, labels, test_size=0.1, random_state=42, stratify = labels)\n",
    "train_examples, test_examples, train_hog_descriptors, test_hog_descriptors, train_labels, test_labels =\\\n",
    "    np.array(train_examples), np.array(test_examples), np.array(train_hog_descriptors), np.array(test_hog_descriptors), np.array(train_labels), np.array(test_labels) \n",
    "#train_hog_descriptors, test_hog_descriptors, train_labels, test_labels = train_test_split(hog_descriptors, labels, test_size=0.1, random_state=42, stratify = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class HOGDescriptor in module cv2.cv2:\n",
      "\n",
      "class HOGDescriptor(builtins.object)\n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, /, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  checkDetectorSize(...)\n",
      " |      checkDetectorSize() -> retval\n",
      " |      .   @brief Checks if detector size equal to descriptor size.\n",
      " |  \n",
      " |  compute(...)\n",
      " |      compute(img[, winStride[, padding[, locations]]]) -> descriptors\n",
      " |      .   @brief Computes HOG descriptors of given image.\n",
      " |      .       @param img Matrix of the type CV_8U containing an image where HOG features will be calculated.\n",
      " |      .       @param descriptors Matrix of the type CV_32F\n",
      " |      .       @param winStride Window stride. It must be a multiple of block stride.\n",
      " |      .       @param padding Padding\n",
      " |      .       @param locations Vector of Point\n",
      " |  \n",
      " |  computeGradient(...)\n",
      " |      computeGradient(img, grad, angleOfs[, paddingTL[, paddingBR]]) -> grad, angleOfs\n",
      " |      .   @brief  Computes gradients and quantized gradient orientations.\n",
      " |      .       @param img Matrix contains the image to be computed\n",
      " |      .       @param grad Matrix of type CV_32FC2 contains computed gradients\n",
      " |      .       @param angleOfs Matrix of type CV_8UC2 contains quantized gradient orientations\n",
      " |      .       @param paddingTL Padding from top-left\n",
      " |      .       @param paddingBR Padding from bottom-right\n",
      " |  \n",
      " |  detect(...)\n",
      " |      detect(img[, hitThreshold[, winStride[, padding[, searchLocations]]]]) -> foundLocations, weights\n",
      " |      .   @brief Performs object detection without a multi-scale window.\n",
      " |      .       @param img Matrix of the type CV_8U or CV_8UC3 containing an image where objects are detected.\n",
      " |      .       @param foundLocations Vector of point where each point contains left-top corner point of detected object boundaries.\n",
      " |      .       @param weights Vector that will contain confidence values for each detected object.\n",
      " |      .       @param hitThreshold Threshold for the distance between features and SVM classifying plane.\n",
      " |      .       Usually it is 0 and should be specified in the detector coefficients (as the last free coefficient).\n",
      " |      .       But if the free coefficient is omitted (which is allowed), you can specify it manually here.\n",
      " |      .       @param winStride Window stride. It must be a multiple of block stride.\n",
      " |      .       @param padding Padding\n",
      " |      .       @param searchLocations Vector of Point includes set of requested locations to be evaluated.\n",
      " |  \n",
      " |  detectMultiScale(...)\n",
      " |      detectMultiScale(img[, hitThreshold[, winStride[, padding[, scale[, finalThreshold[, useMeanshiftGrouping]]]]]]) -> foundLocations, foundWeights\n",
      " |      .   @brief Detects objects of different sizes in the input image. The detected objects are returned as a list\n",
      " |      .       of rectangles.\n",
      " |      .       @param img Matrix of the type CV_8U or CV_8UC3 containing an image where objects are detected.\n",
      " |      .       @param foundLocations Vector of rectangles where each rectangle contains the detected object.\n",
      " |      .       @param foundWeights Vector that will contain confidence values for each detected object.\n",
      " |      .       @param hitThreshold Threshold for the distance between features and SVM classifying plane.\n",
      " |      .       Usually it is 0 and should be specified in the detector coefficients (as the last free coefficient).\n",
      " |      .       But if the free coefficient is omitted (which is allowed), you can specify it manually here.\n",
      " |      .       @param winStride Window stride. It must be a multiple of block stride.\n",
      " |      .       @param padding Padding\n",
      " |      .       @param scale Coefficient of the detection window increase.\n",
      " |      .       @param finalThreshold Final threshold\n",
      " |      .       @param useMeanshiftGrouping indicates grouping algorithm\n",
      " |  \n",
      " |  getDescriptorSize(...)\n",
      " |      getDescriptorSize() -> retval\n",
      " |      .   @brief Returns the number of coefficients required for the classification.\n",
      " |  \n",
      " |  getWinSigma(...)\n",
      " |      getWinSigma() -> retval\n",
      " |      .   @brief Returns winSigma value\n",
      " |  \n",
      " |  load(...)\n",
      " |      load(filename[, objname]) -> retval\n",
      " |      .   @brief loads HOGDescriptor parameters and coefficients for the linear SVM classifier from a file.\n",
      " |      .       @param filename Path of the file to read.\n",
      " |      .       @param objname The optional name of the node to read (if empty, the first top-level node will be used).\n",
      " |  \n",
      " |  save(...)\n",
      " |      save(filename[, objname]) -> None\n",
      " |      .   @brief saves HOGDescriptor parameters and coefficients for the linear SVM classifier to a file\n",
      " |      .       @param filename File name\n",
      " |      .       @param objname Object name\n",
      " |  \n",
      " |  setSVMDetector(...)\n",
      " |      setSVMDetector(svmdetector) -> None\n",
      " |      .   @brief Sets coefficients for the linear SVM classifier.\n",
      " |      .       @param svmdetector coefficients for the linear SVM classifier.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  getDaimlerPeopleDetector(...)\n",
      " |      getDaimlerPeopleDetector() -> retval\n",
      " |      .   @brief Returns coefficients of the classifier trained for people detection (for 48x96 windows).\n",
      " |  \n",
      " |  getDefaultPeopleDetector(...)\n",
      " |      getDefaultPeopleDetector() -> retval\n",
      " |      .   @brief Returns coefficients of the classifier trained for people detection (for 64x128 windows).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  L2HysThreshold\n",
      " |      L2HysThreshold\n",
      " |  \n",
      " |  blockSize\n",
      " |      blockSize\n",
      " |  \n",
      " |  blockStride\n",
      " |      blockStride\n",
      " |  \n",
      " |  cellSize\n",
      " |      cellSize\n",
      " |  \n",
      " |  derivAperture\n",
      " |      derivAperture\n",
      " |  \n",
      " |  gammaCorrection\n",
      " |      gammaCorrection\n",
      " |  \n",
      " |  histogramNormType\n",
      " |      histogramNormType\n",
      " |  \n",
      " |  nbins\n",
      " |      nbins\n",
      " |  \n",
      " |  nlevels\n",
      " |      nlevels\n",
      " |  \n",
      " |  signedGradient\n",
      " |      signedGradient\n",
      " |  \n",
      " |  svmDetector\n",
      " |      svmDetector\n",
      " |  \n",
      " |  winSigma\n",
      " |      winSigma\n",
      " |  \n",
      " |  winSize\n",
      " |      winSize\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cv2.HOGDescriptor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 1296)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hog_descriptors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of classes has to be greater than one; got 1 class",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a4b4103fafbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_hog_descriptors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"clf fitted\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    162\u001b[0m                                        accept_large_sparse=False)\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         sample_weight = np.asarray([]\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_validate_targets\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    547\u001b[0m                                                   classes=cls, y=y_)\n\u001b[0;32m    548\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    550\u001b[0m                 \u001b[1;34m\"The number of classes has to be greater than one; got %d\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m                 \" class\" % len(cls))\n",
      "\u001b[1;31mValueError\u001b[0m: The number of classes has to be greater than one; got 1 class"
     ]
    }
   ],
   "source": [
    "\n",
    "params = {\n",
    "#     'activation': 'relu',\n",
    "#     'batch_size': 128,\n",
    "#     'early_stopping': True,\n",
    "#     'hidden_layer_sizes': (1000, 800, 600),\n",
    "#     'learning_rate': 'adaptive',\n",
    "#     'learning_rate_init': 0.03,\n",
    "#     'n_iter_no_change': 30,\n",
    "#     'random_state': 42,\n",
    "#     'solver': 'sgd',\n",
    "#     'verbose': True\n",
    "    'C': 0.28,\n",
    "    'gamma': 0.0032,\n",
    "    'kernel': 'poly'\n",
    "}\n",
    "\n",
    "model = SVC(**params)\n",
    "clf = make_pipeline(StandardScaler(), model)\n",
    "clf.fit(train_hog_descriptors, train_labels)\n",
    "print(\"clf fitted\")\n",
    "\n",
    "pred = clf.predict(test_hog_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy = (accuracy_score(pred, test_labels)*100)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_labels, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"SVM\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "with mlflow.start_run():\n",
    "    # Log SVM params\n",
    "    for param in params.keys():\n",
    "        mlflow.log_param(param, params[param])\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
